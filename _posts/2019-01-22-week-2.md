---
title:  "Week 2 Writeup"
---

# Week 2

This week covered the basics of forensic computing, forensic tools, and techniques involved with forensic analysis.   
### Forensic computing defined
Forensic computing is the process of identifying, preserving, analyzing, and presenting digital evidence that is in accordance with the law. It's intent is to decipher what exactly happened with a machine, and presenting this to law enforcement for investigative purposes. In essence, one would gather evidence, investigate the evidence, and report it to some authoritative body. There are three general types of forensic computing, live forensics, post-mortem basedd forensics, and network based forensics.   
Live forensics is when one takes the compuer from a location and transports it somewhere else to do analysis. This is obsolete, as a substantial amount of evidence is lost when a computer is unplugged.   
Post-mortem forensics is preferred to live. This type of forensics seeks to gather evidence with memory in tact. This means that the investigator can either analyze on site, or take a memory dump and work with that dump elsewhere.   
Network forensics utilizes network logs to build a case. It is another effective way of doing forensics.   
### Evidence   
In the most simplest terms, evidence is anything that can be used to prove or disprove a fact. Regarding forensics, evidence can be found in many levels, such as the network, operating system, databases, accessories, removable media, or even human testimony. Evidence integrity must always be preserverd and counter measures should be taken to ensure it is not tampered with. For example, cryptographic hashes can be computed on evidence to ensure no changes are made. If a change is made to evidence, the hash will change, alerting the investigator to the change. Investigators can also try to ensure integrity by making evidence extremely hard to access, for example, by locking up hard drives in a vault.
### Volatility   
Volatility is a measure of how susceptible a piece of evidence is to being corrupted or lost. Usually the order of volatility is:   
**System memory**   
**Temporary file systems**   
**Network connections and process tables**   
**Network routing and ARP cache**   
**Acquisitions of disks**   
**Remote logging and data monitoring**   
**physical configuration and network topography**   
**Backups**   
